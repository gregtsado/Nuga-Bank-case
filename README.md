### EXECUTIVE SUMMARY

Nuga Bank, a leading financial institution, embarked on a strategic initiative
to enhance its data exploration and cleaning processes using PySpark. This
case study delves into the project, outlining how Nuga Bank leveraged
PySpark to streamline data preparation, enabling better insights and
decision-making.

### BUSINESS PROBLEM STATEMENT

Nuga Bank faced challenges in effectively exploring and cleaning vast
volumes of financial data, hindering its ability to derive actionable insights.
Data engineers were tasked with addressing the following key issues:

Inefficient manual data exploration and cleaning processes.

Lack of scalability to handle growing data volumes.

Inconsistent data quality leading to inaccurate reporting and analysis.

Complexity in transforming raw data into a structured and
normalized database format.

### Objectives

The primary objectives for data engineers were to:

Implement an automated data exploration and cleaning solution using
PySpark to streamline the process.

Normalize the dataset into a suitable database format (2NF or 3NF) for
improved data integrity and consistency.

Load the cleaned and normalized dataset into a PostgreSQL server for
further analysis and reporting.

### Benefits

The implementation of the PySpark data exploration and cleaning solution
resulted in the following benefits for data engineers:

Efficiency: Automated data exploration and cleaning processes reduced
manual effort and time spent on tedious tasks.

Scalability: PySpark's distributed computing capabilities allowed for
seamless scalability to handle large volumes of financial data.

Data Quality: Improved data quality and consistency through standardized
cleaning and normalization techniques.

Structured Database: Transforming the dataset into a normalized form
facilitated easier database management and querying.

Collaboration: Enhanced collaboration among data engineers and analysts
through standardized data preparation workflows.
